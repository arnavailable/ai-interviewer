{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTHROPIC_API_KEY = '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'\n",
    "GOOGLE_API_KEY = 'AIzaSyBsBhlVsf9OJl1-4_yofzk8bdziDagIZao'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-cloud-speech\n",
    "# pip install moviepy\n",
    "# pip install ffmpeg exe\n",
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several ways to reverse a list in Python. Here are three common methods:\n",
      "\n",
      "1. Using the built-in `reverse()` method:\n",
      "\n",
      "```python\n",
      "def reverse_list(lst):\n",
      "    lst.reverse()\n",
      "    return lst\n",
      "\n",
      "# Example usage\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "reversed_list = reverse_list(my_list)\n",
      "print(reversed_list)  # Output: [5, 4, 3, 2, 1]\n",
      "```\n",
      "\n",
      "2. Using slicing with a step of -1:\n",
      "\n",
      "```python\n",
      "def reverse_list(lst):\n",
      "    return lst[::-1]\n",
      "\n",
      "# Example usage\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "reversed_list = reverse_list(my_list)\n",
      "print(reversed_list)  # Output: [5, 4, 3, 2, 1]\n",
      "```\n",
      "\n",
      "3. Using a loop to reverse the list in-place:\n",
      "\n",
      "```python\n",
      "def reverse_list(lst):\n",
      "    left = 0\n",
      "    right = len(lst) - 1\n",
      "    while left < right:\n",
      "        lst[left], lst[right] = lst[right], lst[left]\n",
      "        left += 1\n",
      "        right -= 1\n",
      "    return lst\n",
      "\n",
      "# Example usage\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "reversed_list = reverse_list(my_list)\n",
      "print(reversed_list)  # Output: [5, 4, 3, 2, 1]\n",
      "```\n",
      "\n",
      "All of these methods will reverse the list. The first two methods create a new reversed list, while the third method modifies the original list in-place. Choose the method that best fits your needs based on whether you want to create a new list or modify the existing one.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    system=\"You are a master coding assistant. Respond with Python solution to the problem.\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"How to reverse a list in Python?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspeech_recognition\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msr\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyaudio\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwave\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecord_audio\u001b[39m(duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, sample_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m44100\u001b[39m, chunk\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def record_audio(duration=5, sample_rate=44100, chunk=1024, channels=2):\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=pyaudio.paInt16,\n",
    "                        channels=channels,\n",
    "                        rate=sample_rate,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=chunk)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(0, int(sample_rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    return frames, sample_rate\n",
    "\n",
    "def save_audio(frames, sample_rate, filename=\"output.wav\"):\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(2)\n",
    "    wf.setsampwidth(pyaudio.PyAudio().get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(sample_rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    \n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Speech recognition could not understand the audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Could not request results from speech recognition service; {e}\"\n",
    "\n",
    "# Main execution\n",
    "duration = 5  # Record for 5 seconds\n",
    "frames, sample_rate = record_audio(duration)\n",
    "save_audio(frames, sample_rate)\n",
    "\n",
    "text = speech_to_text(\"output.wav\")\n",
    "print(\"Transcribed text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     exit()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m  \u001b[38;5;66;03m# Capture frame-by-frame\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m  ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     12\u001b[0m  \u001b[38;5;66;03m# if frame is read correctly ret is True\u001b[39;00m\n\u001b[1;32m     13\u001b[0m  \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    " # Capture frame-by-frame\n",
    " ret, frame = cap.read()\n",
    " \n",
    " # if frame is read correctly ret is True\n",
    " if not ret:\n",
    "    print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "    break\n",
    " # Our operations on the frame come here\n",
    " gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    " # Display the resulting frame\n",
    " cv.imshow('frame', gray)\n",
    " if cv.waitKey(1) == ord('q'):\n",
    "    break\n",
    " \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Job Description\n",
    "\n",
    "with open('job_description.txt', 'r') as file:\n",
    "    job_description = file.read()\n",
    "\n",
    "# Load the Resume\n",
    "\n",
    "with open('resume.txt', 'r') as file:\n",
    "    resume = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to generate a custom questionnaire\n",
    "\n",
    "def generate_questionnaire(job_description, resume):\n",
    "    # Create a list to store the questions\n",
    "    questions = []\n",
    "    \n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#questions = generate_questionnaire(job_description, resume)\n",
    "questions = [\"Hi! How are you doing today?\", \n",
    "             \"What is your name?\", \n",
    "             \"What is your experience in Python programming?\", \n",
    "             \"What is your experience in machine learning?\",\n",
    "             \"What is your experience in deep learning?\",\n",
    "             \"What is your experience in computer vision?\",\n",
    "             \"What is your experience in natural language processing?\",\n",
    "             \"What is your experience in speech recognition?\",\n",
    "             \"What is your experience in audio processing?\",\n",
    "             \"What is your experience in image processing?\",\n",
    "             \"What is your experience in data analysis?\",\n",
    "             \"What is your experience in data visualization?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interviewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Inputting the video file and reading it in different formats\n",
    "\n",
    "cap = cv2.VideoCapture('video.mp4') # Reading the video file\n",
    "\n",
    "# Reading the video file frame by frame\n",
    "\n",
    "while cap.isOpened(): # Checking if the video file is opened\n",
    "    ret, frame = cap.read() # Reading the video file frame by frame, ret is a boolean value that returns true if the frame is available, frame is the image array\n",
    "    if not ret: # If the frame is not available\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    cv2.imshow('AI Interviewer', frame) # Displaying the frame\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'): # If the user presses 'q' key\n",
    "        cap.release() # Releasing the video file\n",
    "        cv2.destroyAllWindows() # Closing all the windows\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Could not find PyAudio; check installation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:108\u001b[0m, in \u001b[0;36mMicrophone.get_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyaudio\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Convert speech to text using microphone input\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mMicrophone() \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSay something...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m     audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mlisten(source)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:80\u001b[0m, in \u001b[0;36mMicrophone.__init__\u001b[0;34m(self, device_index, sample_rate, chunk_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk_size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m chunk_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChunk size must be a positive integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# set up PyAudio\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyaudio_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pyaudio()\n\u001b[1;32m     81\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyaudio_module\u001b[38;5;241m.\u001b[39mPyAudio()\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:110\u001b[0m, in \u001b[0;36mMicrophone.get_pyaudio\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyaudio\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find PyAudio; check installation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LooseVersion\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LooseVersion(pyaudio\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m LooseVersion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.2.11\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: Could not find PyAudio; check installation"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import speech_recognition as sr\n",
    "from google.cloud import speech\n",
    "\n",
    "# Initialize the recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Set up the Google Cloud Speech client\n",
    "client = speech.SpeechClient(credentials=GOOGLE_API_KEY)\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop to continuously get frames\n",
    "while True:\n",
    "    # Read frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Live Video', frame)\n",
    "    \n",
    "    # Check for a key press and exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Convert speech to text using microphone input\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Say something...\")\n",
    "        audio = recognizer.listen(source)\n",
    "        \n",
    "        try:\n",
    "            # Use Google Cloud Speech-to-Text API\n",
    "            audio_data = audio.get_wav_data()\n",
    "            audio_bytes = sr.AudioData(audio_data, source.SAMPLE_RATE, source.SAMPLE_WIDTH)\n",
    "            audio_buffer = audio_bytes.get_raw_data()\n",
    "            \n",
    "            # Configure recognition request\n",
    "            audio_recognition = speech.RecognitionAudio(content=audio_buffer)\n",
    "            config = speech.RecognitionConfig(\n",
    "                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "                sample_rate_hertz=source.SAMPLE_RATE,\n",
    "                language_code=\"en-US\"\n",
    "            )\n",
    "            \n",
    "            # Recognize speech\n",
    "            response = client.recognize(config=config, audio=audio_recognition)\n",
    "            \n",
    "            for result in response.results:\n",
    "                print(\"You said: \" + result.alternatives[0].transcript)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "\n",
    "# Release the capture and destroy all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No ffmpeg exe could be found. Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract audio from computer vision video\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m video \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mVideoFileClip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m audio \u001b[38;5;241m=\u001b[39m video\u001b[38;5;241m.\u001b[39maudio\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/moviepy/editor.py:36\u001b[0m\n\u001b[1;32m     33\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPYGAME_HIDE_SUPPORT_PROMPT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Clips\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mVideoFileClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImageSequenceClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageSequenceClip\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_webfile\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/moviepy/video/io/VideoFileClip.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAudioFileClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioFileClip\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Clip\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffmpeg_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FFMPEG_VideoReader\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/moviepy/audio/io/AudioFileClip.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAudioClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioClip\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FFMPEG_AudioReader\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAudioFileClip\u001b[39;00m(AudioClip):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/moviepy/audio/AudioClip.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mproglog\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffmpeg_audiowriter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ffmpeg_audiowrite\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mClip\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Clip\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m requires_duration\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/moviepy/audio/io/ffmpeg_audiowriter.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mproglog\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEVNULL\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_setting\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m requires_duration\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFFMPEG_AudioWriter\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/moviepy/config.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m FFMPEG_BINARY\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffmpeg-imageio\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffmpeg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_exe\n\u001b[0;32m---> 36\u001b[0m     FFMPEG_BINARY \u001b[38;5;241m=\u001b[39m get_exe()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m FFMPEG_BINARY\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto-detect\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m try_cmd([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffmpeg\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imageio/plugins/ffmpeg.py:173\u001b[0m, in \u001b[0;36mget_exe\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exe\u001b[39m():  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for imageio_ffmpeg.get_ffmpeg_exe()\"\"\"\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m imageio_ffmpeg\u001b[38;5;241m.\u001b[39mget_ffmpeg_exe()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imageio_ffmpeg/_utils.py:33\u001b[0m, in \u001b[0;36mget_ffmpeg_exe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exe\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Nothing was found\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo ffmpeg exe could be found. Install ffmpeg on your system, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set the IMAGEIO_FFMPEG_EXE environment variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No ffmpeg exe could be found. Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable."
     ]
    }
   ],
   "source": [
    "# Extract audio from computer vision video\n",
    "\n",
    "import moviepy.editor as mp\n",
    "\n",
    "video = mp.VideoFileClip(\"video.mp4\")\n",
    "audio = video.audio\n",
    "audio.write_audiofile(\"audio.mp3\")\n",
    "\n",
    "# Import the necessary libraries\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Create a function to convert speech to text\n",
    "\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer() # Creating a recognizer object\n",
    "    with sr.AudioFile(audio_file) as source: # Opening the audio file\n",
    "        audio = recognizer.record(source) # Recording the audio\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio) # Recognizing the audio using Google Speech Recognition\n",
    "        return text # Returning the text\n",
    "    except sr.UnknownValueError: # If the audio is not recognized\n",
    "        return \"Speech recognition could not understand the audio\"\n",
    "    except sr.RequestError as e: # If there is an error in the request\n",
    "        return f\"Could not request results from speech recognition service; {e}\"\n",
    "    \n",
    "# Convert speech to text\n",
    "\n",
    "text = speech_to_text(\"audio.mp3\")\n",
    "\n",
    "# Print the transcribed text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define speech to text function\n",
    "\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    \n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Speech recognition could not understand the audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Could not request results from speech recognition service; {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get response from LLM\n",
    "\n",
    "def get_response(text, conversation):\n",
    "    conversation.append({\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": text}]})\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        system=\"You are a master coding assistant. Respond with Python solution to the problem.\",\n",
    "        messages = conversation\n",
    "    )\n",
    "    return message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text to speech function\n",
    "\n",
    "def text_to_speech(text, filename=\"output.wav\"):\n",
    "    tts = gTTS(text)\n",
    "    tts.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to play audio\n",
    "\n",
    "def play_audio(filename=\"output.wav\"):\n",
    "    playsound(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('frame', gray)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Save the frame as an image\n",
    "    cv2.imwrite('frame.jpg', frame)\n",
    "\n",
    "    # Convert the image to text\n",
    "    text = ocr_image('frame.jpg')\n",
    "\n",
    "    # Get response from LLM\n",
    "    response = get_response(text)\n",
    "\n",
    "    # Convert the response to speech\n",
    "    text_to_speech(response)\n",
    "\n",
    "    # Play the audio\n",
    "    play_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grading(question, answer):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
